{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split,GridSearchCV,cross_val_score,KFold\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from joblib import dump\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "##读取数据\n",
    "Database=pd.read_csv(\"Database2023429.csv\",index_col=None)\n",
    "X=Database.iloc[:,:-1]\n",
    "rt=Database.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#用get_dummies方法对名称字段进行onehot编码\n",
    "X=pd.DataFrame(X)\n",
    "X_needencoder=X.iloc[:,:7]\n",
    "X_needencoder_dummy=pd.get_dummies(X_needencoder,columns=X_needencoder.columns)\n",
    "X.drop(['核苷种类','A溶剂','A添加剂种类mmol','A添加剂种类percent','B溶剂',\n",
    "        'B添加剂种类mmol','B添加剂种类percent'],axis=1,inplace=True)\n",
    "X_needencoder_dummy.to_csv('X_needencoder_dummy.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "# 特征缩放\n",
    "scaler = StandardScaler()\n",
    "X_num = X.select_dtypes(include=['int','float64'])  # 选取连续的数值变量\n",
    "X_num_scaled = scaler.fit_transform(X_num)\n",
    "X_num_scaled = pd.DataFrame(X_num_scaled, columns=X_num.columns)\n",
    "X=pd.concat([X_num_scaled,X_needencoder_dummy],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将数据集拆分为训练集、验证集、测试集\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, rt, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda1\\envs\\env_name\\lib\\site-packages\\sklearn\\base.py:402: UserWarning: X has feature names, but SelectFromModel was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\Anaconda1\\envs\\env_name\\lib\\site-packages\\sklearn\\base.py:402: UserWarning: X has feature names, but SelectFromModel was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "# 特征选择\n",
    "model = xgb.XGBRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, Y_train)\n",
    "selector = SelectFromModel(model, prefit=True, threshold='mean')\n",
    "X_train = selector.transform(X_train)\n",
    "X_test = selector.transform(X_test)\n",
    "\n",
    "# 定义参数范围\n",
    "params = {\n",
    "    'max_depth': np.arange(3, 10, 2),\n",
    "    'learning_rate': [0.01, 0.1, 0.5],\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'reg_alpha': [0, 0.1, 0.5],\n",
    "    'reg_lambda': [0, 0.1, 0.5],\n",
    "}\n",
    "\n",
    "# 使用GridSearchCV进行超参数调整\n",
    "xgb_model = xgb.XGBRegressor(random_state=42)\n",
    "grid_search = GridSearchCV(xgb_model, param_grid=params, \n",
    "                           scoring='neg_mean_squared_error', cv=kf)\n",
    "grid_search.fit(X, rt)\n",
    "# 输出最优参数\n",
    "print('最优超参数：', grid_search.best_params_)\n",
    "\n",
    "##逻辑回归的目标函数\n",
    "dtrain = xgb.DMatrix(X_train, label=Y_train)\n",
    "target_params = {'objective': ['reg:linear', 'reg:logistic', 'binary:logistic'], \n",
    "          'eta': [0.01, 0.1, 0.5]}\n",
    "xgb_model = xgb.XGBRegressor(random_state=42)\n",
    "grid_search_target = GridSearchCV(xgb_model, param_grid=target_params, \n",
    "                           scoring='neg_mean_squared_error', cv=kf)\n",
    "grid_search_target.fit(X, rt)\n",
    "\n",
    "# 输出最优参数\n",
    "print('最优参数：', grid_search_target.best_params_)\n",
    "##model = xgb.train(params, dtrain, num_boost_round=100)\n",
    "\n",
    "# 训练模型\n",
    "model = xgb.XGBRegressor(**grid_search.best_params_,\n",
    "                         **grid_search_target.best_params_, random_state=42)\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "test_score = model.score(X_test, Y_test)\n",
    "score=model.score(X_test,Y_test)\n",
    "print('模型性能：',score)\n",
    "\n",
    "##交叉验证\n",
    "scores = cross_val_score(model, X, rt, cv=kf, scoring='neg_mean_squared_error')\n",
    "rmse_scores = np.sqrt(-scores)\n",
    "print('均方根误差：', rmse_scores.mean())\n",
    "\n",
    "\n",
    "\n",
    "dump(model, 'XGBoost_model.joblib')\n",
    "\n",
    "# 绘制回归曲线\n",
    "model.fit(X_train, Y_train)\n",
    "y_pred_train = model.predict(X_train)\n",
    "y_pred_test = model.predict(X_test)\n",
    "plt.scatter(Y_train, y_pred_train, label='train')\n",
    "plt.scatter(Y_test, y_pred_test, label='test')\n",
    "plt.plot([0, 1], [0, 1], '--', color='black')\n",
    "plt.xlabel('true')\n",
    "plt.ylabel('predicted')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_name",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
